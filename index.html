<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xinyu Wei - Personal Website</title>
    <meta name="description" content="Xinyu Wei's personal website">

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/susu.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
    <!-- æ·»åŠ è‡ªå®šä¹‰æ ·å¼ -->
    <style>
        /* ä½¿ç”¨Comic Sans MSæˆ–å…¶ä»–å¤‡é€‰å¡é€šé£æ ¼å­—ä½“ */
        .name-header h1 {
            font-family: "Comic Sans MS", "Comic Sans", cursive;
        }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- personal information -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <div class="name-header h1">
                    <h1 >Xinyu Wei(é­ å¿ƒå®‡)</h1>
                </div>
                <div class="profile-section">
                    <!-- <p class="bio">ğŸ“ PhD candidate at <img src="images/polyu.png" class="university-logo" alt="polyu Logo"> <span class="polyu-red">PolyU</span>, supervised by <a href="https://scholar.google.com/citations?user=tAK5l1IAAAAJ">Prof. ZHANG Lei John(FIEEE)</a></p> -->
                    <p class="bio">ğŸ I am sincerely seeking <strong>PhD opportunities for Fall 2025</strong>! I explored various paths and discovered that research is truly my passion and I hope to make research my lifelong career!</p>
                    <p class="bio">ğŸ” I study <strong>Large Language/Vision Models, Modality Alignment, Image Generation</strong>.</p>
                    <!-- <p class="bio">ğŸ‘” Me and my friends run a thriving micro-startup offering <strong>full-stack AI courses for newbies</strong> - ping our <a href="https://nerdnet.cn/">NerdNet</a>(Work-In-Process).</p> -->
                    <p class="bio">ğŸ¤© <strong>Feel free to reach out for any academic collabs !!</strong></p>
                    
                    <!-- æ·»åŠ è”ç³»æ–¹å¼ -->
                    <div class="contact-links">
                        <a href="https://scholar.google.com/citations?user=UAcIZ2kAAAAJ" class="bio">
                            <span class="contact-icon">ğŸ“</span> Google Scholar
                        </a>
                        


                        <a href="mailto:allen_wei@stu.pku.edu.cn" class="bio">
                            <span class="contact-icon">âœ‰ï¸</span> allen_wei@stu.pku.edu.cn
                        </a>
                    </div>
                </div>
              </td>
              <td style="padding:2.5%;width:37%;max-width:99%;vertical-align:middle">
                <a href="images/allen.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/allen_54.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <!-- Education -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <div class="section-header">
                <h2>Education</h2>
              </div>
              <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
              <p class="bio">
                [2022-2025] M.S. in Software Engineering as <strong>Merit Student</strong>ğŸ‰, <a href="https://www.pku.edu.cn/"><img src="images/pku_logo.png" class="university-logo" alt="PKU Logo"></a> <span class="pku-red">Peking University</span>, Supervised by <a href="https://scholar.google.com/citations?user=voqw10cAAAAJ&hl=en">Prof. Shanghang Zhang</a>
              </p>
              <p class="bio">
                [2018-2022] B.E. in Computer Science with <strong>Distinction</strong>ğŸ‰, <a href="https://www.whu.edu.cn/"><img src="images/Wuhan_University_Logo.png" class="university-logo" alt="WHU Logo"></a> <span class="whu-green">Wuhan University</span>
              </p>
            </td>
          </tr>
          </tbody></table>
          <!-- News -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <div class="section-header">
                  <h2>News</h2>
                </div>
                <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
                <p class="bio">
                  [2025.01] Three papers accepted by ICLR 2025ğŸ‰
                </p>
                <p class="bio">
                  [2024.03] One paper accepted by CVPR 2024ğŸ‰, One paper accepted by CVPR WorhshopğŸ’ª
                </p>
                <p class="bio">
                  [2020.02] Meritorious Winner (Top 6% Globally) at <a href="https://www.comap.com/contests/mcm-icm">Mathematical Contest in Modeling (MCM)ğŸ‰</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          <!-- Internship -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <div class="section-header">
                <h2>Internship</h2>
              </div>
              <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
              <p class="bio">
                [2025.01-Now] Intern at Y-LabğŸ“–,   <strong>OPPO</strong>, Supervised by <a href="https://scholar.google.com/citations?user=tAK5l1IAAAAJ">Prof. ZHANG Lei John(FIEEE)</a>
              </p>
              <p class="bio">
                [2024.04-2024.10] Intern at General Vision GroupğŸ“–,  <strong>Shanghai AI Lab</strong>, Supervised by <a href="https://scholar.google.com/citations?user=_go6DPsAAAAJ">Dr. Peng Gao</a>
              </p>
              <p class="bio">
                [2023.04-2024.04] Intern at NLC GroupğŸ”§,  <strong>MicroSoft Research Asia</strong>, Supervised by <a href="https://www.microsoft.com/en-us/research/people/yanxia/">Dr. Yan Xia</a>
              </p>
            </td>
          </tr>
          </tbody></table>
          



          <!-- Selected Publications -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <div class="section-header">
                    <h2>Selected Publications</h2>
                  </div>
                  <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
                </td>
              </tr>
            </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- paper -->
          <tr >
            <td style="padding-top:4px;padding-bottom:4px;padding-left:16px;padding-right:16px;width:20%;vertical-align:middle">
              <img src='images/mavis.jpg' width=100% alt="MAVIS paper thumbnail">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2407.08739">
            <span class="papertitle">MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine</span>
              </a>
              <br>
              Renrui Zhang<sup>*</sup>, <strong>Xinyu Wei<sup>*</sup></strong>, Dongzhi Jiang, Ziyu Guo, Yichi Zhang, Chengzhuo Tong, Jiaming Liu, Aojun Zhou, Shanghang Zhang, Peng Gao, Hongsheng Li
              <br>
              <em><strong>ICLR2025</strong></em>
              <br>
              <a href="https://arxiv.org/abs/2407.08739">Arxiv</a>
              /
              <a href="https://github.com/ZrrSkywalker/MAVIS">CodeğŸ”¥</a>
              <p></p>
              <p>
                ğŸ“ The first public large-scale multi-modal mathematical dataset for tuning large VLMs
              </p>
            </td>
          </tr>

          <!-- paper -->
          <tr >
            <td style="padding-top:4px;padding-bottom:4px;padding-left:16px;padding-right:16px;width:20%;vertical-align:middle">
              <img src='images/pixwizard.jpg' width=100% alt="PixWizard paper thumbnail">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2409.15278">
            <span class="papertitle">PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions</span>
              </a>
              <br>
              Weifeng Lin<sup>*</sup>, <strong>Xinyu Wei<sup>*</sup></strong>, Renrui Zhang<sup>*</sup>, Le Zhuo<sup>*</sup>, Shitian Zhao, Siyuan Huang, Huan Teng, Junlin Xie, Yu Qiao, Peng Gao, Hongsheng Li
              <br>
              <em><strong>ICLR2025</strong></em>
              <br>
              <a href="https://arxiv.org/abs/2409.15278">Arxiv</a>
              /
              <a href="https://github.com/AFeng-x/PixWizard?tab=readme-ov-file">CodeğŸ”¥</a>
              <p></p>
              <p>
                ğŸ§‘â€ğŸ¨ A unified DiT framework and large-scale dataset with any-resolution processing, capable of 20+ vision tasks including both understanding and generating through language instructions.
              </p>
            </td>
          </tr>

          <!-- paper -->
          <tr >
            <td style="padding-top:4px;padding-bottom:4px;padding-left:16px;padding-right:16px;width:20%;vertical-align:middle">
              <img src='images/DnU.jpg' width=100% alt="Draw-and-Understand paper thumbnail">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2403.20271">
            <span class="papertitle">Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want</span>
              </a>
              <br>
              Weifeng Lin<sup>*</sup>, <strong>Xinyu Wei<sup>*</sup></strong>, Ruichuan An, Peng Gao, Bocheng Zou, Yulin Luo, Siyuan Huang, Shanghang Zhang, Hongsheng Li
              <br>
              <em><strong>ICLR2025</strong></em>
              <br>
              <a href="https://arxiv.org/abs/2403.20271">Arxiv</a>
              /
              <a href="https://github.com/AFeng-x/Draw-and-Understand">CodeğŸ”¥</a>
              /
              <a href="https://draw-and-understand.github.io/">Project Page</a>
              <p></p>
              <p>
                ğŸ¨ A general framework integrating visual prompting (points/boxes/shapes) through MDVP-Instruct-Data (1.2M multi-domain triplets) and MDVP-Bench, boosting pixel-level comprehension and visual prompt interaction for MLLMs.
              </p>
            </td>
          </tr>

          <!-- paper -->
          <tr >
            <td style="padding-top:4px;padding-bottom:4px;padding-left:16px;padding-right:16px;width:20%;vertical-align:middle">
              <img src='images/cdcca.jpg' width=100% alt="CDCCA paper thumbnail">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.16279">
            <span class="papertitle">Cloud-Device Collaborative Learning for Multimodal Large Language Models</span>
              </a>
              <br>
              Guanqun Wang, Jiaming Liu, Chenxuan Li, Junpeng Ma, Yuan Zhang, <strong>Xinyu Wei</strong>, Kevin Zhang, Maurice Chong, Ray Zhang, Yijiang Liu, Shanghang Zhang
              <br>
              <em><strong>CVPR2024</strong></em>
              <br>
              <a href="https://arxiv.org/pdf/2312.16279">Arxiv</a>
              <p></p>
              <p>
                ğŸ¤– A lifelong-learning framework that boosts compressed MLLMs' on-device performance via uncertainty-guided token filtering, adapter-based knowledge transfer, and dynamic weight quantization.
              </p>
            </td>
          </tr>


        <!-- Selected Preprints -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <div class="section-header">
                    <h2>Selected Preprints</h2>
                  </div>
                  <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
                </td>
              </tr>
            </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- paper -->
          <tr >
            <td style="padding-top:4px;padding-bottom:4px;padding-left:16px;padding-right:16px;width:20%;vertical-align:middle">
              <img src='images/mrmllm.jpg' width=100% alt="MAVIS paper thumbnail">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2406.15768">
            <span class="papertitle">MR-MLLM: Mutual Reinforcement of Multimodal Comprehension and Vision Perception</span>
              </a>
              <br>
              Guanqun Wang<sup>*</sup>, <strong>Xinyu Wei<sup>*</sup></strong>, Jiaming Liu, Ray Zhang, Yichi Zhang, Kevin Zhang, Maurice Chong, Shanghang Zhang
              <br>
              <br>
              <a href="https://arxiv.org/abs/2406.15768">Arxiv</a>
              <p></p>
              <p>
                ğŸ”§ The pioneering studies investigated the infusion of heterogeneous visual information into MLLMs through <strong>multi-task vision encoder integration</strong>
              </p>
            </td>
          </tr>

        <!-- Hobbies -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:16px;width:100%;vertical-align:middle">
            <div class="section-header">
              <h2>Hobbies</h2>
            </div>
            <div style="border-top: 1px solid #eaeaea; margin-bottom: 16px;"></div>
            <p class="bio">
              <a href="https://www.xiaohongshu.com/user/profile/5c0a6e4e00000000070193d4">Photography ğŸ“¸</a>, Body Building ğŸ’ª, Movie ğŸ¬,  BasketBall ğŸ€,  Video Games ğŸ®,  Snorkeling ğŸ¤¿
            </p>
            <p class="bio">
              I read history and philosophy ğŸ“–
            </p>
            <p class="bio">
              I travel all around the world ğŸŒ
            </p>
          </td>
        </tr>
      </tbody></table>
          
        </td>
      </tr>
    </table>
  </body>
</html>
